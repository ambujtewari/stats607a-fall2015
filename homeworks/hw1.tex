\documentclass{article}

\input{stats607-header}

\begin{document}


\author{Ambuj Tewari}
\title{STATS 607A (Fall '14): Assignment 1\\
Due: Sep 30, 2014 23:59:59}
\date{Sep 15, 2014}

\maketitle

\begin{center}
This version: 4.0 (corrected submission procedure and permission settings)
\end{center}

\subsection*{Ways to earn extra credit}

\begin{itemize}
\item +1 for all real bugs in the already supplied code that you find and report to the instructor.
\item +1 for each problem where your code is in the top 10 percentile (top 5 students) in terms of running time.
\item +1 for each python script where Python style guide checker {\tt pep8} doesn't report any issues. You can test for any style guide issues yourself by typing
{\tt pep8 <python-script>} on the shell prompt.

\end{itemize}

\subsection*{How to turn in?}

Create a directory called {\tt stats607-fall2014} (case-sensitive) in the {\tt Public} directory already present in your home directory on any of the Bayes machines.
Make it readable for the instructor and GSI by typing:\\
\verb#fs sa ~/Public/stats607-fall2014/ -acl tewaria read kamwong read# \\
on the Bayes command prompt. Then create a sub-directory called {\tt assignment\_one} within the 607 directory. Make that readable too for us by typing:\\
\verb#fs sa ~/Public/stats607-fall2014/assignment_one/ -acl tewaria read kamwong read# \\
We will try to find the
following 4 files in your home directory after the submission deadline:\\
{\tt assignment\_one\_kmeans.py} \\
{\tt assignment\_one\_optimization.py} \\
{\tt assignment\_one\_nearest\_neighbor.py} \\
{\tt assignment\_one\_answers.pdf} \\

The first 3 files should be python scripts that run without any error message. The last file should be a PDF file with answers to all questions below. Make sure the 4 files
themselves readable to us. You can check whether permissions are ok by typing:
\begin{verbatim}
fs listacl ~/Public/stats607-fall2014
fs listacl ~/Public/stats607-fall2014/assignment_one
\end{verbatim}
You should see 2 lines in the output (in each case) that say: (under ``Normal rights:")\\
{\tt tewaria rl}\\
{\tt kamwong rl}

\section{K-means (10 points)}

In this problem, we will implement the \href{http://en.wikipedia.org/wiki/K-means_clustering\#Standard_algorithm}{K-means algorithm}. Download a test dataset ``seeds" from:\\
\url{http://archive.ics.uci.edu/ml/datasets/seeds} \\
In the file {\tt seeds\_dataset.txt}, there are 210 instances of dimension 7 along with a categorical label (1, 2, or 3). Download an (incomplete!) python script by following the following
link:\\
\href{https://github.com/ambujtewari/stats607a-fall2014/blob/master/homeworks/assignment_one_kmeans.py}{\tt assignment\_one\_kmeans.py} \\
Click on the ``Raw" button on the top right and save the file as {\tt assignment\_one\_kmeans.py}.

Open the python script in your favorite text editors. You will see a bunch of places where a comment says {\tt TASK x.y(.z)}. These are the places where you have to supply your
own code.\\
{\bf Important:} Please only change/add code where the tasks require you to do so (sometimes you'll have to replace a {\tt pass} statement with real code, sometimes you'll be changing existing statements). Please {\em don't} modify the existing code and comments anywhere else! We might use automated scripts to grade your code and not following this suggestion will break those scripts.

We will now briefly describe your tasks. If something is unclear, please don't hesitate to email the instructor and/or GSI.

\subsection{Reading in the data (1 point)}

We will read in the instances into two lists: {\tt instances} and {\tt labels}. The former will a list of 7-dimensional instance. An instance will itself be represented using a list of length 7.
The latter will be a list of the labels (note that the label occurs at the end of each line).

Task 1.1 has 2 subtasks: 1.1.1 and 1.1.2.

\subsection{Finding number of unique labels (1 point)}

Finish the definition of the function {\tt num\_unique\_labels} so that it finds out how many unique labels are there in its argument {\tt labels}. Make sure it returns 3 for the labels obtained
from the seeds dataset.

\subsection{Implementing K-means++ (2 points)}

\href{http://en.wikipedia.org/wiki/K-means\%2B\%2B}{K-means++} is an enhanced version of the classic K-means algorithm. It only differs from the classic algorithm in the way it initializes the $K$ centers.
Implement the function {\tt kmeans\_plus\_plus} so that this enhanced initialization is available by supplying the optional argument {\tt init} to {\tt cluster\_using\_kmeans}. Its default value is ``random" (in this case,
the initial centers are simply chosen at uniformly at random without replacement).

Note that this task hasn't been broken down into precisely defined subtasks deliberately. We want to see how well you document your code when given complete freedom. We also want to see how much
variation we see in your solutions to this task. Remember those extra credits for running time -- this is the task where to get them by beating your fellow students' approaches!

\subsection{Cluster assignment step of K-means (2 points)}

Implement the function {\tt assign\_cluster\_ids}.

Task 1.4 has 2 subtasks: 1.4.1 and 1.4.2.

\subsection{Center re-computation step of K-means (2 points)}

Implement the function {\tt recompute\_centers}.

Task 1.5 has 2 subtasks: 1.5.1 and 1.5.2.

\subsection{Running the script and discussing the output (2 points)}

Once you have supplied all missing pieces of the code, run the script using:\\
{\tt python assignment\_one\_kmeans.py}

Answer the following questions:
\begin{description}
\item[Q. 1.1]
How does the kmeans clustering compare to the provided labels? On how many instances do they disagree?
\item[Q. 1.2]
How does the kmeans++ clustering compare to the provided labels? How does it compare to the kmeans clustering? Is there any difference at all?
\end{description}


\section{Simple Optimization (12 points)}

In the problem, we will implement two simple optimization algorithms: gradient descent and coordinate descent. A gradient descent iteration is simple:
\[
x \gets x - \alpha \nabla f(x)
\]
where $\alpha > 0$ is a step size parameter.

\subsection{Implement gradient descent given gradient evaluator (2 points)}

Download the incomplete code from:
\href{https://github.com/ambujtewari/stats607a-fall2014/blob/master/homeworks/assignment_one_optimization.py}{\tt assignment\_one\_optimization.py} \\
Also download:
\href{https://github.com/ambujtewari/stats607a-fall2014/blob/master/homeworks/losses.py}{\tt losses.py} \\
and make sure you put the two files in the same directory (the former {\tt import}s the latter).

Implement the function {\tt gradient\_descent}. Note that the argument {\tt func\_grad} gives you the gradient at an arbitrary point. The gradient 
as well as the iterates have dimension {\tt dim} and are both represented as lists of floating point numbers (of length {\tt dim})

Task 2.1 has 2 subtasks: 2.1.1 and 2.1.2.

\subsection{Implement coordinate descent given partial derivative evaluator (2 points)}

Implement the function {\tt coordinate\_descent}. This is the algorithm whose single iteration looks like:\\

\noindent
{\bf For} $j$ {\bf in} $i_1, i_2, \ldots, i_d$ \\
$\phantom{aaaa} x_j \gets x_j - \alpha [\nabla f(x)]_j$\\

\noindent
where $[\nabla f(x)]_j$ is the partial derivative $\partial f/\partial x_j$ evaluated at $x$.

There are two version of coordinate descent: cyclic and random. In the cyclic version, the sequence of coordinates we change is deterministic. It is simply $i_1=1,
i_2=2, i_3=3, \ldots$ (of course, remember that, in Python, the indices will start from $0$ not $1$).
In the random version, the sequence $i_1, i_2, \ldots, i_d$ is a random draw from the coordinates $1$ through $d$ (let us say with replacement). You have to implement
both versions. Note that the argument {\tt func\_grad\_1d} is a function that takes two arguments, $x$ (first) and $j$ (second), and gives you $[\nabla f(x)_j]$.

Task 2.2 has 3 subtasks: 2.2.1, 2.2.2 and 2.2.3 (0.5, 0.5 and 1 point respectively).

\subsection{Loss and loss gradient evaluators (4 points)}

We will test the two optimization algorithms on functions that arise in maximum-likelihood estimation problems in regression/classification using linear models.
In particular, we will consider (unconstrained) minimization of
\begin{equation}\label{loss}
f(\beta) = \frac{1}{n} \sum_{i=1}^n \ell(\beta^\top X_i, Y_i)
\end{equation}
where $X_i \in \reals^d, Y_i \in \reals$ and $\ell(t, y)$ is a non-negative loss functions such as the squared loss $(t-y)^2$ or the logistic loss
$\log(1+\exp(-yt))$ (used in classification settings where $y \in \{-1,+1\}$). These two losses along with the gradients $\ell'(t,y)$ (w.r.t. the first argument $t$)
are already defined in {\tt losses.py} for you. What you have to do is to define the 3 functions: {\tt loss\_calculator}, {\tt loss\_grad\_calculator},
{\tt loss\_grad\_1d\_calculator} using the equation~\eqref{loss} above and the equations~\eqref{loss_grad} and~\eqref{loss_grad_1d} below respectively:
\begin{equation}\label{loss_grad}
\nabla f(\beta) = \frac{1}{n} \sum_{i=1}^n \ell'(\beta^\top X_i, Y_i) X_i
\end{equation}
\begin{equation}\label{loss_grad_1d}
[\nabla f(\beta)]_j = \frac{1}{n} \sum_{i=1}^n \ell'(\beta^\top X_i, Y_i) X_{i,j}
\end{equation}
where $X_{i,j}$ is the $j$th feature/covariate of the $i$th example/input. Note that {\tt loss\_calculator} is actually already almost complete except that you will
need to implement a helper function {\tt vector\_dot} that simply returns
$u^\top v = \sum_{j=1}^d u_jv_j$ for two vectors $u$ and $v$ (represented as lists of floats).

Task 2.3 has 4 subtasks: 2.3.1 through 2.3.4.

\subsection{Testing the optimization routines on regression and logistic regression (2 points)}

The {\tt main()} function first creates a regression data set with continuous responses $Y_i$ and then creates a binary classification data set with
binary valued labels $Y_i \in \{-1,+1\}$. It runs gradient descent and coordinate descent on both data sets using certain fixed choices for initial
points and step sizes (leave them as they are). Your task it to create appropriate functions that can be passed to gradient desct and coordinate
descent so that the entire ${\tt main()}$ function executes properly.

Task 2.4 has 2 subtasks: 2.4.1 and 2.4.2

\subsection{Running the script and discussing the output (2 points)}

After completing all tasks, run the script using:\\
{\tt python assignment\_one\_optimization.py} \\
(making sure that {\tt losses.py} is in the same directory) and answer the following questions.

\begin{description}
\item[Q. 2.1]
Which optimization method took less time? Does your answer depend on whether you're talking about squared loss or logistic loss case?
\item[Q. 2.2]
Do the optimization methods return reasonable solutions? How does the returned solution compare to the true parameter vector?
If we ran the optimization to more and more iterations, would you expect the returned solution to converge to the true parameter?
\end{description}


\section{Nearest Neighbor Classification (8 points)}

In this part, we will implement the k-nearest neighbor classification algorithm for a multiclass classification and compute 10-fold cross-validation
errors on a randomly shuffled version of {\tt seeds\_dataset.txt} which is available here:\\
\href{https://github.com/ambujtewari/stats607a-fall2014/blob/master/homeworks/datasets/seeds_dataset_shuffled.txt}{\tt seeds\_dataset\_shuffled.txt} \\
(Make sure you click on the ``Raw"" button to download the raw .txt file).
Download the incomplete code from:\\
\href{https://github.com/ambujtewari/stats607a-fall2014/blob/master/homeworks/assignment_one_nearest_neighbor.py}{\tt assignment\_one\_nearest\_neighbor.py}

\subsection{Creating folds (2 points)}

Your first task is to write the function {\tt get\_fold\_indices} that'll be used to create the different folds in 10-fold cross validation. It takes three arguments:
{\tt n} (sample size), {\tt num\_folds} (total number of folds) and {\tt fold\_id} (which fold are we creating?). It should return a tuple of lists: {\tt
train\_indices, test\_indices}. It's behavior is best illustrated by an example:
\begin{verbatim}
>>> get_fold_indices(10, 5, 0)  # 10 samples/5-fold CV/get train-test indices for fold 0
([2, 3, 4, 5, 6, 7, 8, 9], [0, 1])
>>> get_fold_indices(10, 5, 1)
([0, 1, 4, 5, 6, 7, 8, 9], [2, 3])
>>> get_fold_indices(10, 5, 2)
([0, 1, 2, 3, 6, 7, 8, 9], [4, 5])
>>> get_fold_indices(10, 5, 3)
([0, 1, 2, 3, 4, 5, 8, 9], [6, 7])
>>> get_fold_indices(10, 5, 4)
([0, 1, 2, 3, 4, 5, 6, 7], [8, 9])
\end{verbatim}

As you can see, when {\tt n} is divisible by {\tt fold\_size}, all splits are of equal size. When {\tt n} is not divisible by {\tt fold\_size}, the last split will have a slightly larger
test indices list and a slightly smaller train indices list. For example, when we have 12 samples and we're doing 5-fold CV, we should get the following behavior:
\begin{verbatim}
>>> get_fold_indices(12, 5, 0)
([2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1])
>>> get_fold_indices(12, 5, 1)
([0, 1, 4, 5, 6, 7, 8, 9, 10, 11], [2, 3])
>>> get_fold_indices(12, 5, 2)
([0, 1, 2, 3, 6, 7, 8, 9, 10, 11], [4, 5])
>>> get_fold_indices(12, 5, 3)
([0, 1, 2, 3, 4, 5, 8, 9, 10, 11], [6, 7])
>>> get_fold_indices(12, 5, 4)
([0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11])
\end{verbatim}

Task 3.1 has 3 subtasks: 3.1.1, 3.1.2 and 3.1.3 (.5, .5 and 1 points)

\subsection{k-nearest neighbor classifier (3 points)}

Implement the function {\tt nn\_classifier}. Given a {\tt point} to classify, we first sort examples in {\tt train\_data} according to their distances from {\tt point}. Then we
want to look at the labels of the $k$-nearest data points. These should get stored in {\tt nearest\_k\_labels}. Then we find the label that occurs the most in 
{\tt nearest\_k\_labels} and return it. If there are ties, we break them at random.

Task 3.2 has 3 subtasks: 3.2.1 through 3.2.3.

\subsection{Computing classification error (1 point)}

Implement the function {\tt classification\_error}. Given a {\tt classifier} and a {\tt data} set with {\tt labels}, it should figure out the number of examples in the data set on
which the classifier's label disagrees with the provided label. Finally, it should return the error rate: total number of errors divided by sample size.

\subsection{Creating and processing the folds (1 point)}

For each fold, use the indices returned to {\tt get\_fold\_indices} to create a classifier trained on the training and test data sets for that fold. Then
evaluate the error rate of that classifier on the test set of that fold.

Task 3.4 has 2 subtasks: 3.4.1 and 3.4.2

\subsection{Running the script and discussing the output (1 point)}

Once all functions have been implemented run the script (it will read data from {\tt seeds\_dataset\_shuffled.txt} and will import definitions from {\tt assignment\_one\_kmeans.py}. So
make sure these two files are present in the same directory. Answer the following question.

\begin{description}
\item[Q. 3.1]
Which $k$ values gave you lowest $10$-fold CV errors? If you run the same code on the unshuffled data {\tt seeds\_dataset.txt}, would you see higher or lower errors?
Why?
\end{description}


\end{document}
