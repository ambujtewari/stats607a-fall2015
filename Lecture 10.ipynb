{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll cover:\n",
    "\n",
    "1. [Reading and writing text](#Reading-and-writing-text)\n",
    "2. [Reading from databases](#Reading-from-databases)\n",
    "3. [Reading from web APIs](#Reading-from-web-APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 main reading & writing functions in pandas we will discuss are:\n",
    "\n",
    "* `read_csv()` to read comma separated data (we saw this in the last lecture)\n",
    "* `to_csv()` to write comnna separated data\n",
    "\n",
    "But before we get into the details of these, let us create some data files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematician</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gauss</th>\n",
       "      <td>German</td>\n",
       "      <td>1777</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euler</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>1707</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lagrange</th>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laplace</th>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Nationality  Born  Died\n",
       "Mathematician                        \n",
       "Gauss              German  1777  1855\n",
       "Euler               Swiss  1707  1783\n",
       "Lagrange           French  1736  1813\n",
       "Laplace            French  1749  1827"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([['German', 1777, 1855],\n",
    "                   ['Swiss', 1707, 1783],\n",
    "                   ['French', 1736, 1813],\n",
    "                   ['French', 1749, 1827]],\n",
    "                  index=['Gauss', 'Euler', 'Lagrange', 'Laplace'],\n",
    "                  columns=['Nationality', 'Born', 'Died'])\n",
    "df.index.name = 'Mathematician'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('math.csv')  # export to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematician,Nationality,Born,Died\r\n",
      "Gauss,German,1777,1855\r\n",
      "Euler,Swiss,1707,1783\r\n",
      "Lagrange,French,1736,1813\r\n",
      "Laplace,French,1749,1827\r\n"
     ]
    }
   ],
   "source": [
    "!cat math.csv  # run shell command to examine file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mathematician</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gauss</td>\n",
       "      <td>German</td>\n",
       "      <td>1777</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Euler</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1707</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lagrange</td>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mathematician Nationality  Born  Died\n",
       "0         Gauss      German  1777  1855\n",
       "1         Euler       Swiss  1707  1783\n",
       "2      Lagrange      French  1736  1813\n",
       "3       Laplace      French  1749  1827"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df  # delete the DataFrame\n",
    "df = pd.read_csv('math.csv')  # read it back in\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't quite give our original DataFrame back. We need to tell `read_csv` to use the first column (column 0) as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematician</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gauss</th>\n",
       "      <td>German</td>\n",
       "      <td>1777</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euler</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>1707</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lagrange</th>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laplace</th>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Nationality  Born  Died\n",
       "Mathematician                        \n",
       "Gauss              German  1777  1855\n",
       "Euler               Swiss  1707  1783\n",
       "Lagrange           French  1736  1813\n",
       "Laplace            French  1749  1827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('math.csv', index_col=0)  # use columns 0 as index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save a DataFrame without the header and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('math.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German,1777,1855\r\n",
      "Swiss,1707,1783\r\n",
      "French,1736,1813\r\n",
      "French,1749,1827\r\n"
     ]
    }
   ],
   "source": [
    "!cat math.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematicians</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gauss</th>\n",
       "      <td>German</td>\n",
       "      <td>1777</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euler</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>1707</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lagrange</th>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laplace</th>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Nationality  Born  Died\n",
       "Mathematicians                        \n",
       "Gauss               German  1777  1855\n",
       "Euler                Swiss  1707  1783\n",
       "Lagrange            French  1736  1813\n",
       "Laplace             French  1749  1827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('math.csv', names=['Nationality', 'Born', 'Died'])  # read and supply columns names\n",
    "df.index = ['Gauss', 'Euler', 'Lagrange', 'Laplace']   # supply the index\n",
    "df.index.name = 'Mathematicians'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large files, it might make sense to read them in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 French mathematicians.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('math.csv')  # save again for index and header\n",
    "chunks = pd.read_csv('math.csv', chunksize=1)  # chunksize is in no. of lines\n",
    "french_count = 0\n",
    "for piece in chunks:\n",
    "    french_count += piece['Nationality'][0] == 'French'\n",
    "print 'Found %d French mathematicians.' % french_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematicians:Nationality:Born:Died\n",
      "Gauss:German:1777:1855\n",
      "Euler:Swiss:1707:1783\n",
      "Lagrange:French:1736:1813\n",
      "Laplace:French:1749:1827\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "df.to_csv(sys.stdout, sep=':')  # can use a separator other than comma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often the data you want to work with resides in a [relational database management system](http://en.wikipedia.org/wiki/Relational_database_management_system) (RDBMS). Some common commerical RDBMS implementations are: Oracle Database, Microsoft SQL server, MySQL and IBM DB2. [SQLite](http://www.sqlite.org/) is a freely available lightweight, disk-based (doesn't require a database server) database engine. In python, the package `sqlite3` provides an interface to SQLite.\n",
    "\n",
    "SQL (Structured Query Language) is a language used to interact with a database. A quick introduction to SQL can be found here:\n",
    "\n",
    "http://www.w3schools.com/sql/\n",
    "\n",
    "The SQL command to create a table in a database is `CREATE` (SQL queries are not case-sensitive: `CREATE` is the same as `create`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE math\n",
    "(Mathematician VARCHAR(10),\n",
    " Nationality VARCHAR(10),\n",
    " Born INTEGER,\n",
    " Died INTEGER\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our first query, let us connect to a database and execute the query. In SQLite, databases are stored on disk as files. However, we can create an in-memory database denoted by the special name `:memory:`.\n",
    "\n",
    "Any query that changes the database, need to be committed to ensure that the change is visible to other connections to the database that might be open at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(':memory:')  # connect to an in-memory database\n",
    "con.execute(query)  # execute the query\n",
    "con.commit()  # commit the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an empty table in the `:memory:` database. Let us insert some values into it using the SQL command `INSERT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con.execute(\"INSERT INTO math VALUES('Gauss', 'German', 1777, 1855)\")  # insert values\n",
    "con.commit()  # and commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the table has a single row in it. Let us retrieve contents of the table using the SQL command `SELECT`. The result of executing a `SELECT` command is a *cursor*. You can think of it as an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Gauss', u'German', 1777, 1855)\n"
     ]
    }
   ],
   "source": [
    "cursor = con.execute('SELECT * FROM math')\n",
    "for row in cursor:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us insert some more values in our table. The `executemany` method is useful for executing many commands for the same type. The placeholder `?` gets replaces by the values supplied in the list argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = [('Euler', 'Swiss', 1707, 1783),\n",
    "          ('Lagrange', 'French', 1736, 1813),\n",
    "          ('Laplace', 'French', 1749, 1827)]\n",
    "con.executemany(\"INSERT INTO math VALUES(?, ?, ?, ?)\", values)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that a cursor can be used an iterators. If you want one row, you can use the `fetchone()` method. If you you want all rows, you can use the `fetchall()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching one row...\n",
      "(u'Gauss', u'German', 1777, 1855)\n",
      "Fetching all remaining rows...\n",
      "[(u'Euler', u'Swiss', 1707, 1783), (u'Lagrange', u'French', 1736, 1813), (u'Laplace', u'French', 1749, 1827)]\n"
     ]
    }
   ],
   "source": [
    "cursor = con.execute('SELECT * FROM math')\n",
    "print \"Fetching one row...\"\n",
    "print cursor.fetchone()\n",
    "print \"Fetching all remaining rows...\"\n",
    "print cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides a convenient way to convert results of SQL queries in DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mathematician</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gauss</td>\n",
       "      <td>German</td>\n",
       "      <td>1777</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Euler</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>1707</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lagrange</td>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mathematician Nationality  Born  Died\n",
       "0         Gauss      German  1777  1855\n",
       "1         Euler       Swiss  1707  1783\n",
       "2      Lagrange      French  1736  1813\n",
       "3       Laplace      French  1749  1827"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas.io.sql as sql\n",
    "sql.read_sql('SELECT * FROM math', con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try retrieving only French mathematicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mathematician</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lagrange</td>\n",
       "      <td>French</td>\n",
       "      <td>1736</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>French</td>\n",
       "      <td>1749</td>\n",
       "      <td>1827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mathematician Nationality  Born  Died\n",
       "0      Lagrange      French  1736  1813\n",
       "1       Laplace      French  1749  1827"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql.read_sql('SELECT * FROM math WHERE Nationality=\"French\"', con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from web APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [Twitter Search API](https://dev.twitter.com/rest/public/search) to search for tweets. The API returns results in the [JSON format](http://en.wikipedia.org/wiki/JSON). You will remember that IPython notebooks (such as this document!) are also encoded in the JSON format.\n",
    "\n",
    "But before we can build a search query and execute it on twitter, we need to authenticate. We will use Twitter's [Application-only authentication](https://dev.twitter.com/oauth/application-only). The way this works is:\n",
    "\n",
    "1. Our (Python) application will encodes its *consumer key* and *consumer secret* into a specially encoded set of credentials.\n",
    "2. Then the application will make a request to exchange these credentials for a *bearer token*.\n",
    "3. When accessing the API, our application will use the *bearer token* to authenticate.\n",
    "\n",
    "Let us work on Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib2 import urlopen, Request  # to create HTTP requests and open URLs\n",
    "import base64  # for base64 encoding\n",
    "import json  # for handling the JSON format\n",
    "\n",
    "consumer_key = 'dNcn9ZjPJ6dSaXJMYnVgna7jg'  # our app's consumer key\n",
    "consumer_secret = open('consumer_secret', 'r').read().strip()  # read secret (should not be made public) from file\n",
    "\n",
    "bearer_token = '%s:%s' % (consumer_key, consumer_secret)\n",
    "encoded_bearer_token = base64.b64encode(bearer_token.encode('ascii'))  # bearer token needs to be base64 encoded\n",
    "request = Request('https://api.twitter.com/oauth2/token')\n",
    "request.add_header('Content-Type',\n",
    "                   'application/x-www-form-urlencoded;charset=UTF-8')\n",
    "request.add_header('Authorization',\n",
    "                   'Basic %s' % encoded_bearer_token.decode('utf-8'))\n",
    "request_data = 'grant_type=client_credentials'.encode('ascii')\n",
    "request.add_data(request_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Request object ready, let us send our request to get a bearer token to Twitter (Step 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = urlopen(request)  # make the request\n",
    "raw_data = response.read().decode('utf-8')  # read the raw results in JSON format\n",
    "data = json.loads(raw_data)  # decode JSON into Python data structures\n",
    "bearer_token = data['access_token']  # extract the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the bearer token to search (Step 3). Let us search for tweets containing \"data science\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://api.twitter.com/1.1/search/tweets.json?q=data%20science'  # search for \"data science\"\n",
    "request = Request(url)\n",
    "request.add_header('Authorization', 'Bearer %s' % bearer_token)  # use the bearer token from Step 2\n",
    "response = urlopen(request)  # make the request\n",
    "raw_data = response.read().decode('utf-8')  # results in raw JSON\n",
    "data = json.loads(raw_data)  # decode JSON into Python data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point `data` is a dictionary with just two keys: `search_metadata` and `statuses`. The latter has the tweets inside a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'search_metadata', u'statuses']\n"
     ]
    }
   ],
   "source": [
    "print data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'contributors': None,\n",
      " u'coordinates': None,\n",
      " u'created_at': u'Mon Oct 12 14:49:05 +0000 2015',\n",
      " u'entities': {u'hashtags': [{u'indices': [106, 119],\n",
      "                              u'text': u'agreenskills'}],\n",
      "               u'symbols': [],\n",
      "               u'urls': [{u'display_url': u'kaggle.com/competitions',\n",
      "                          u'expanded_url': u'https://www.kaggle.com/competitions',\n",
      "                          u'indices': [38, 61],\n",
      "                          u'url': u'https://t.co/MmLCB6Cc7A'}],\n",
      "               u'user_mentions': [{u'id': 292832796,\n",
      "                                   u'id_str': u'292832796',\n",
      "                                   u'indices': [94, 105],\n",
      "                                   u'name': u'Bal\\xe1zs K\\xe9gl',\n",
      "                                   u'screen_name': u'balazskegl'}]},\n",
      " u'favorite_count': 0,\n",
      " u'favorited': False,\n",
      " u'geo': None,\n",
      " u'id': 653583170017853440,\n",
      " u'id_str': u'653583170017853440',\n",
      " u'in_reply_to_screen_name': None,\n",
      " u'in_reply_to_status_id': None,\n",
      " u'in_reply_to_status_id_str': None,\n",
      " u'in_reply_to_user_id': None,\n",
      " u'in_reply_to_user_id_str': None,\n",
      " u'is_quote_status': False,\n",
      " u'lang': u'en',\n",
      " u'metadata': {u'iso_language_code': u'en', u'result_type': u'recent'},\n",
      " u'place': None,\n",
      " u'possibly_sensitive': False,\n",
      " u'retweet_count': 0,\n",
      " u'retweeted': False,\n",
      " u'source': u'<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
      " u'text': u'data science competitions from Kaggle https://t.co/MmLCB6Cc7A - new to me, being described by @balazskegl #agreenskills',\n",
      " u'truncated': False,\n",
      " u'user': {u'contributors_enabled': False,\n",
      "           u'created_at': u'Mon Mar 16 15:43:58 +0000 2009',\n",
      "           u'default_profile': False,\n",
      "           u'default_profile_image': False,\n",
      "           u'description': u'Maths \\u2192 Pattern Recognition \\u2192 Medical Research \\u2192 Computing \\u2192 Networking \\u2192 Supercomputing \\u2192 Digital Preservation \\u2192 Training \\u2192 Digital Curation',\n",
      "           u'entities': {u'description': {u'urls': []},\n",
      "                         u'url': {u'urls': [{u'display_url': u'dcc.ac.uk',\n",
      "                                             u'expanded_url': u'http://www.dcc.ac.uk/',\n",
      "                                             u'indices': [0, 22],\n",
      "                                             u'url': u'http://t.co/TjC3VwVi1m'}]}},\n",
      "           u'favourites_count': 1897,\n",
      "           u'follow_request_sent': None,\n",
      "           u'followers_count': 1433,\n",
      "           u'following': None,\n",
      "           u'friends_count': 567,\n",
      "           u'geo_enabled': False,\n",
      "           u'has_extended_profile': False,\n",
      "           u'id': 24711165,\n",
      "           u'id_str': u'24711165',\n",
      "           u'is_translation_enabled': False,\n",
      "           u'is_translator': False,\n",
      "           u'lang': u'en',\n",
      "           u'listed_count': 87,\n",
      "           u'location': u'UK',\n",
      "           u'name': u'Kevin Ashley',\n",
      "           u'notifications': None,\n",
      "           u'profile_background_color': u'642D8B',\n",
      "           u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme10/bg.gif',\n",
      "           u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme10/bg.gif',\n",
      "           u'profile_background_tile': True,\n",
      "           u'profile_image_url': u'http://pbs.twimg.com/profile_images/248761894/avamug_june_normal.jpg',\n",
      "           u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/248761894/avamug_june_normal.jpg',\n",
      "           u'profile_link_color': u'FF0000',\n",
      "           u'profile_sidebar_border_color': u'65B0DA',\n",
      "           u'profile_sidebar_fill_color': u'7AC3EE',\n",
      "           u'profile_text_color': u'3D1957',\n",
      "           u'profile_use_background_image': True,\n",
      "           u'protected': False,\n",
      "           u'screen_name': u'kevingashley',\n",
      "           u'statuses_count': 12321,\n",
      "           u'time_zone': u'London',\n",
      "           u'url': u'http://t.co/TjC3VwVi1m',\n",
      "           u'utc_offset': 3600,\n",
      "           u'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "import pprint  # import pretty print module\n",
    "pprint.pprint(data['statuses'][0])  # print the first tweet, it is a Python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Oct 12 14:49:05 +0000 2015</td>\n",
       "      <td>data science competitions from Kaggle https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Oct 12 14:48:21 +0000 2015</td>\n",
       "      <td>SAS Academy for Data Science Certification Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Oct 12 14:48:13 +0000 2015</td>\n",
       "      <td>RT @iradche: 90+ Active Blogs on Analytics, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Oct 12 14:47:25 +0000 2015</td>\n",
       "      <td>ReTw Soccermetric: Red cards and race: Importa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Oct 12 14:46:40 +0000 2015</td>\n",
       "      <td>Evolution of NASA Earth Science Data Systems i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mon Oct 12 14:46:34 +0000 2015</td>\n",
       "      <td>Data Science Analyst http://t.co/JgSliV9au2 #work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon Oct 12 14:46:29 +0000 2015</td>\n",
       "      <td>hatebu: Building Data Science Teams - http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mon Oct 12 14:46:04 +0000 2015</td>\n",
       "      <td>RT @MBNConsilium_RR: MBN Data Science Event, L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mon Oct 12 14:46:02 +0000 2015</td>\n",
       "      <td>Looking for a #Year #Round Intern-Product Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon Oct 12 14:45:19 +0000 2015</td>\n",
       "      <td>Data Science Bootcamps – The Best Courses of 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mon Oct 12 14:44:50 +0000 2015</td>\n",
       "      <td>@Yolibeans @CFigueres @COP21 @WSJ @business @G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mon Oct 12 14:43:59 +0000 2015</td>\n",
       "      <td>#Aliyun #DataCenter – Aliyun Opens Second Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mon Oct 12 14:43:04 +0000 2015</td>\n",
       "      <td>Building Data Science Teams https://t.co/PZfOK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mon Oct 12 14:41:09 +0000 2015</td>\n",
       "      <td>Looking forward to the @DataSciTechScot meetup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mon Oct 12 14:40:53 +0000 2015</td>\n",
       "      <td>RT @alexbiebricher: Do you like #data, #satell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Mon Oct 12 14:49:05 +0000 2015   \n",
       "1   Mon Oct 12 14:48:21 +0000 2015   \n",
       "2   Mon Oct 12 14:48:13 +0000 2015   \n",
       "3   Mon Oct 12 14:47:25 +0000 2015   \n",
       "4   Mon Oct 12 14:46:40 +0000 2015   \n",
       "5   Mon Oct 12 14:46:34 +0000 2015   \n",
       "6   Mon Oct 12 14:46:29 +0000 2015   \n",
       "7   Mon Oct 12 14:46:04 +0000 2015   \n",
       "8   Mon Oct 12 14:46:02 +0000 2015   \n",
       "9   Mon Oct 12 14:45:19 +0000 2015   \n",
       "10  Mon Oct 12 14:44:50 +0000 2015   \n",
       "11  Mon Oct 12 14:43:59 +0000 2015   \n",
       "12  Mon Oct 12 14:43:04 +0000 2015   \n",
       "13  Mon Oct 12 14:41:09 +0000 2015   \n",
       "14  Mon Oct 12 14:40:53 +0000 2015   \n",
       "\n",
       "                                                 text  \n",
       "0   data science competitions from Kaggle https://...  \n",
       "1   SAS Academy for Data Science Certification Pro...  \n",
       "2   RT @iradche: 90+ Active Blogs on Analytics, Bi...  \n",
       "3   ReTw Soccermetric: Red cards and race: Importa...  \n",
       "4   Evolution of NASA Earth Science Data Systems i...  \n",
       "5   Data Science Analyst http://t.co/JgSliV9au2 #work  \n",
       "6   hatebu: Building Data Science Teams - http://t...  \n",
       "7   RT @MBNConsilium_RR: MBN Data Science Event, L...  \n",
       "8   Looking for a #Year #Round Intern-Product Mana...  \n",
       "9   Data Science Bootcamps – The Best Courses of 2...  \n",
       "10  @Yolibeans @CFigueres @COP21 @WSJ @business @G...  \n",
       "11  #Aliyun #DataCenter – Aliyun Opens Second Data...  \n",
       "12  Building Data Science Teams https://t.co/PZfOK...  \n",
       "13  Looking forward to the @DataSciTechScot meetup...  \n",
       "14  RT @alexbiebricher: Do you like #data, #satell...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the text and created_at fields and convert in pandas DataFrame\n",
    "tweets_df = pd.DataFrame(data['statuses'], columns=['created_at', 'text'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Oct 12 14:49:23 +0000 2015</td>\n",
       "      <td>RT @dataiku: 9 Steps to Become a Data Scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Oct 12 14:49:08 +0000 2015</td>\n",
       "      <td>#AzureML is one beautiful poster, makes it ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Oct 12 14:48:55 +0000 2015</td>\n",
       "      <td>RT 3DBillionaire: Leverage your #Enterprise wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Oct 12 14:46:21 +0000 2015</td>\n",
       "      <td>The price of the #InternetOfThings - http://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Oct 12 14:45:15 +0000 2015</td>\n",
       "      <td>RT @ORESYS: Petit-déjeuner à suivre demain en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mon Oct 12 14:45:06 +0000 2015</td>\n",
       "      <td>RT @ORESYS: Petit-déjeuner à suivre demain en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon Oct 12 14:44:51 +0000 2015</td>\n",
       "      <td>#Amazon Announces #InternetOfThings Platform, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mon Oct 12 14:44:01 +0000 2015</td>\n",
       "      <td>RT @moorejh: Here’s how one #healthcare org is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mon Oct 12 14:43:46 +0000 2015</td>\n",
       "      <td>Analyzing the #InternetOfThings: https://t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon Oct 12 14:43:33 +0000 2015</td>\n",
       "      <td>RT @moorejh: Here’s how one #healthcare org is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mon Oct 12 14:43:32 +0000 2015</td>\n",
       "      <td>RT @moorejh: Here’s how one #healthcare org is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mon Oct 12 14:42:58 +0000 2015</td>\n",
       "      <td>RT @KirkDBorne: Are CEOs ignoring #BigData #Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mon Oct 12 14:42:33 +0000 2015</td>\n",
       "      <td>moorejh: Here’s how one #healthcare org is mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mon Oct 12 14:41:22 +0000 2015</td>\n",
       "      <td>RT @moorejh: Statisticians court data scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mon Oct 12 14:41:06 +0000 2015</td>\n",
       "      <td>Here’s how one #healthcare org is making use o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Mon Oct 12 14:49:23 +0000 2015   \n",
       "1   Mon Oct 12 14:49:08 +0000 2015   \n",
       "2   Mon Oct 12 14:48:55 +0000 2015   \n",
       "3   Mon Oct 12 14:46:21 +0000 2015   \n",
       "4   Mon Oct 12 14:45:15 +0000 2015   \n",
       "5   Mon Oct 12 14:45:06 +0000 2015   \n",
       "6   Mon Oct 12 14:44:51 +0000 2015   \n",
       "7   Mon Oct 12 14:44:01 +0000 2015   \n",
       "8   Mon Oct 12 14:43:46 +0000 2015   \n",
       "9   Mon Oct 12 14:43:33 +0000 2015   \n",
       "10  Mon Oct 12 14:43:32 +0000 2015   \n",
       "11  Mon Oct 12 14:42:58 +0000 2015   \n",
       "12  Mon Oct 12 14:42:33 +0000 2015   \n",
       "13  Mon Oct 12 14:41:22 +0000 2015   \n",
       "14  Mon Oct 12 14:41:06 +0000 2015   \n",
       "\n",
       "                                                 text  \n",
       "0   RT @dataiku: 9 Steps to Become a Data Scientis...  \n",
       "1   #AzureML is one beautiful poster, makes it ver...  \n",
       "2   RT 3DBillionaire: Leverage your #Enterprise wi...  \n",
       "3   The price of the #InternetOfThings - http://t....  \n",
       "4   RT @ORESYS: Petit-déjeuner à suivre demain en ...  \n",
       "5   RT @ORESYS: Petit-déjeuner à suivre demain en ...  \n",
       "6   #Amazon Announces #InternetOfThings Platform, ...  \n",
       "7   RT @moorejh: Here’s how one #healthcare org is...  \n",
       "8   Analyzing the #InternetOfThings: https://t.co/...  \n",
       "9   RT @moorejh: Here’s how one #healthcare org is...  \n",
       "10  RT @moorejh: Here’s how one #healthcare org is...  \n",
       "11  RT @KirkDBorne: Are CEOs ignoring #BigData #Da...  \n",
       "12  moorejh: Here’s how one #healthcare org is mak...  \n",
       "13  RT @moorejh: Statisticians court data scientis...  \n",
       "14  Here’s how one #healthcare org is making use o...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.twitter.com/1.1/search/tweets.json?q=%23datascience'  # search for the hashtag #datascience\n",
    "request = Request(url)\n",
    "request.add_header('Authorization', 'Bearer %s' % bearer_token)  # use the bearer token from Step 2\n",
    "response = urlopen(request)  # make the request\n",
    "raw_data = response.read().decode('utf-8')  # results in raw JSON\n",
    "data = json.loads(raw_data)  # decode JSON into Python data structures\n",
    "hashtag_tweets_df = pd.DataFrame(data['statuses'], columns=['created_at', 'text'])\n",
    "hashtag_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up temporary files in the end\n",
    "!rm math.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
